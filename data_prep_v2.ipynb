{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "joined-avatar",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mediterranean-ballet",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "colored-continent",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "admissions = pd.read_csv('mimic_iii_data/ADMISSIONS.csv.gz',compression='gzip').drop('ROW_ID',axis=1)\n",
    "\n",
    "patients   = pd.read_csv('mimic_iii_data/PATIENTS.csv.gz',compression='gzip').drop('ROW_ID',axis=1)\n",
    "\n",
    "dx         = pd.read_csv('mimic_iii_data/DIAGNOSES_ICD.csv.gz',compression='gzip').drop('ROW_ID',axis=1)\n",
    "\n",
    "drg        = pd.read_csv('mimic_iii_data/DRGCODES.csv.gz',compression='gzip').drop('ROW_ID',axis=1)\n",
    "drg.drop_duplicates(inplace=True)\n",
    "drg.DESCRIPTION = drg.DESCRIPTION.map(lambda x: x.lower() if pd.notna(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "veterinary-tolerance",
   "metadata": {},
   "outputs": [],
   "source": [
    "maps = {'diagnosis_na'      :'',\n",
    "        'admission_location':'',\n",
    "        'admission_na'      :'',\n",
    "        'ethnicity'         :'',\n",
    "        'diagnoses'         :'',\n",
    "        'icd'               :'',\n",
    "        'drg'               :''}\n",
    "\n",
    "for n in maps.keys():\n",
    "    with open(f'{n}_map.pkl', 'rb') as f:\n",
    "        maps[n] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complicated-receipt",
   "metadata": {},
   "source": [
    "# Create DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "racial-richards",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DF\n",
    "X = admissions[['HADM_ID','ADMISSION_TYPE','ADMISSION_LOCATION','LANGUAGE','ETHNICITY','DIAGNOSIS']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dependent-soldier",
   "metadata": {},
   "source": [
    "### Add Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "subject-cigarette",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Lenght of Stay\n",
    "admissions.DISCHTIME = pd.to_datetime(admissions.DISCHTIME)\n",
    "admissions.ADMITTIME = pd.to_datetime(admissions.ADMITTIME)\n",
    "admissions.DEATHTIME = pd.to_datetime(admissions.DEATHTIME)\n",
    "\n",
    "admissions['LOS'] = (admissions.DISCHTIME - admissions.ADMITTIME).dt.days\n",
    "# some discharge times are earlier than admission -- all seem to have presented DOA\n",
    "X['LOS'] = admissions.LOS.map(lambda x: 0 if x<0 else x)\n",
    "# Add column of pts who died within 4 hours of admission\n",
    "X['DOA'] = ((admissions.DEATHTIME - admissions.ADMITTIME).dt.total_seconds()/3600<4).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "simple-actress",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patient age and gender\n",
    "T = pd.merge(admissions[['SUBJECT_ID','HADM_ID','ADMITTIME']],\n",
    "             patients[['SUBJECT_ID','DOB','GENDER']],\n",
    "             on='SUBJECT_ID')\n",
    "T_old    = T[T.DOB < '2000-01-01']\n",
    "T        = T[T.DOB > '2000-01-01']\n",
    "\n",
    "T['AGE'] =((pd.to_datetime(T.ADMITTIME).dt.date - \n",
    "            pd.to_datetime(T.DOB).dt.date).values//(3.1689*10**16)).astype(int)\n",
    "T_old['AGE'] = 90\n",
    "T = T.append(T_old)\n",
    "X = X.merge(T[['HADM_ID','AGE','GENDER']],on='HADM_ID')\n",
    "X.GENDER = X.GENDER.map(lambda x: 0 if x=='M' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "satellite-practice",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ICD9 codes\n",
    "X = X.merge(dx[['HADM_ID','ICD9_CODE']][dx.SEQ_NUM==1],on='HADM_ID')\\\n",
    "     .rename(columns = {'ICD9_CODE':f'DIAGNOSIS_1'})\n",
    "    \n",
    "X = X.merge(dx.groupby('HADM_ID').SEQ_NUM.max(),on='HADM_ID')\\\n",
    "     .rename(columns = {'SEQ_NUM':f'N_DIAGNOSES'})           \\\n",
    "     .set_index('HADM_ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "right-hepatitis",
   "metadata": {},
   "source": [
    "# Fill missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "adaptive-german",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADMISSION_TYPE:\n",
      "\t0\n",
      "ADMISSION_LOCATION:\n",
      "\t0\n",
      "LANGUAGE:\n",
      "\t25299\n",
      "ETHNICITY:\n",
      "\t0\n",
      "DIAGNOSIS:\n",
      "\t15\n",
      "LOS:\n",
      "\t0\n",
      "DOA:\n",
      "\t0\n",
      "AGE:\n",
      "\t0\n",
      "GENDER:\n",
      "\t0\n",
      "DIAGNOSIS_1:\n",
      "\t0\n",
      "N_DIAGNOSES:\n",
      "\t0\n"
     ]
    }
   ],
   "source": [
    "for col in X.columns:\n",
    "    print(f'{col}:\\n\\t{X[col].isna().sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "harmful-granny",
   "metadata": {},
   "source": [
    "### Fill Missing dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "australian-briefs",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute using missing diagnosis map\n",
    "X.DIAGNOSIS = X[['DIAGNOSIS','DIAGNOSIS_1']].set_index('DIAGNOSIS_1').DIAGNOSIS\\\n",
    "                                            .fillna(maps['diagnosis_na']).values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worthy-front",
   "metadata": {},
   "source": [
    "### Fill Missing Admisssion Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "visible-prague",
   "metadata": {},
   "outputs": [],
   "source": [
    "# narrow admission categories using admission location map\n",
    "X.ADMISSION_LOCATION = X.ADMISSION_LOCATION.map(maps['admission_location'])\n",
    "X.ADMISSION_TYPE     = X.ADMISSION_TYPE.map(lambda x: 'EMERGENCY' if x=='URGENT' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "structural-fossil",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NEWBORN                          300\n",
       "LIVER LACERATION                   1\n",
       "ANKLE FRACTURE                     1\n",
       "CARDIAC ARREST                     1\n",
       "PNEUMOPERTONEUM                    1\n",
       "GUN SHOT WOUND                     1\n",
       "RESPIRATORY FAILURE,UROSEPSIS      1\n",
       "Name: DIAGNOSIS, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check diagnosis for patients missing admission location\n",
    "X[pd.isna(X.ADMISSION_LOCATION)].DIAGNOSIS.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "sophisticated-hawaii",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "REFERRAL    7520\n",
       "TRANSFER       3\n",
       "Name: ADMISSION_LOCATION, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check predominant admission location for newboorn dx\n",
    "X[X.DIAGNOSIS=='NEWBORN'].ADMISSION_LOCATION.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "alone-columbia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute using missing admission location map \n",
    "X.ADMISSION_LOCATION = X[['DIAGNOSIS','ADMISSION_LOCATION']].set_index('DIAGNOSIS').ADMISSION_LOCATION\\\n",
    "                                                            .fillna(maps['admission_na']).values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strategic-bailey",
   "metadata": {},
   "source": [
    "### Fill Missing Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "regulated-external",
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing values assumed to be English. Map to binary, indicating presence of language barrier\n",
    "X.LANGUAGE = X.LANGUAGE.map(lambda x: 1 if x=='ENGL' else 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "enabling-record",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for any remaining NANs\n",
    "X.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "federal-toolbox",
   "metadata": {},
   "source": [
    "# Narrow categorical\n",
    "### Broaden ethnicity categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "communist-houston",
   "metadata": {},
   "outputs": [],
   "source": [
    "# narrow ethnicity categories (english vs. non-english speaking)\n",
    "X.ETHNICITY = X.ETHNICITY.map(maps['ethnicity']) #drop unknown after dummies created"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unnecessary-annex",
   "metadata": {},
   "source": [
    "### Map ICD9 codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "progressive-split",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diagnosis:\n",
      "\tGI_INFECTION\n",
      "Diagnosis:\n",
      "\tTB\n",
      "Diagnosis:\n",
      "\tBACTERIAL_INFECTION_OTHER\n",
      "Diagnosis:\n",
      "\tSEPSIS\n",
      "Diagnosis:\n",
      "\tHIV\n",
      "Diagnosis:\n",
      "\tVIRAL_CNS\n",
      "Diagnosis:\n",
      "\tVIRAL_HEPATITIS\n",
      "Diagnosis:\n",
      "\tVIRUS_OTHER\n",
      "Diagnosis:\n",
      "\tCHLAMIDIA\n",
      "Diagnosis:\n",
      "\tARTHROPOD_BORN_INFECTION\n",
      "Diagnosis:\n",
      "\tSYPHILIS\n",
      "Diagnosis:\n",
      "\tDERMATOPHYTOSIS\n",
      "Diagnosis:\n",
      "\tCANDIDIASIS\n",
      "Diagnosis:\n",
      "\tMYCOSES_OTHER\n",
      "Diagnosis:\n",
      "\tHELMINTHIASIS\n",
      "Diagnosis:\n",
      "\tINFECTION_OTHER\n",
      "Diagnosis:\n",
      "\tSARCOIDOSIS\n",
      "Diagnosis:\n",
      "\tPOLIO\n",
      "Diagnosis:\n",
      "\tORAL_PHARYNGERAL_CANCER\n",
      "Diagnosis:\n",
      "\tESOPHAGUS_STOMACH_CANCER\n",
      "Diagnosis:\n",
      "\tINTESTINAL_CANCER\n",
      "Diagnosis:\n",
      "\tLIVER_CANCER\n",
      "Diagnosis:\n",
      "\tGALLBLADDER_CANCER\n"
     ]
    }
   ],
   "source": [
    "# map ICD9 codes to broader categories using icd map\n",
    "for regx,diag in maps['icd'].items():\n",
    "    print(f'Diagnosis:\\n\\t{diag}')\n",
    "    dx[f'{diag}'] = dx.ICD9_CODE.str.match(regx,na=False).astype(int)\n",
    "dx = dx.drop('ICD9_CODE',axis=1).groupby('HADM_ID').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "higher-characteristic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove admission that were present in ICD9 DF but missing from admission DF\n",
    "missing_patients = set(dx.index) - set(X.index)\n",
    "dx = dx.drop(missing_patients)\n",
    "X  = X.join(dx.drop(['SUBJECT_ID','SEQ_NUM'],axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifth-denial",
   "metadata": {},
   "source": [
    "### Pull Keywords from DRGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stopped-andorra",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull tags from DRGs using DRG map\n",
    "def get_descriptor(s,descriptor):\n",
    "    return 1 if s[-len(descriptor):]==descriptor else 0\n",
    "def strip_descriptor(s,descriptor):\n",
    "    return s[:-len(descriptor)-1] if s[-len(descriptor):]==descriptor else s\n",
    "\n",
    "tags = ['COMA','SEVERE','VENTILATED','SX','TRANSPLANT','FAILURE','CANCER','ID','NEONATE']\n",
    "\n",
    "drg_copy = drg.copy()\n",
    "drg_copy.DESCRIPTION = drg.DESCRIPTION.map(maps['drg'])\n",
    "for tag in tags:\n",
    "    drg_copy['TAG_'+tag] = drg_copy.DESCRIPTION.map(lambda x: get_descriptor(x,tag), na_action='ignore')\n",
    "    drg_copy.DESCRIPTION = drg_copy.DESCRIPTION.map(lambda x: strip_descriptor(x,tag), na_action='ignore')\n",
    "\n",
    "tags = ['TAG_'+tag for tag in tags]\n",
    "drg_copy  = drg_copy[tags+['DESCRIPTION','HADM_ID']].drop_duplicates()\n",
    "drg_copy  = pd.get_dummies(drg_copy,prefix='TAG',columns=['DESCRIPTION'])\\\n",
    "              .groupby('HADM_ID').sum().applymap(lambda x: 1 if x>=1 else 0)\n",
    "drg_copy.drop('TAG_OTHER',axis=1,inplace=True)\n",
    "X = X.merge(drg_copy,on='HADM_ID',how='left')\n",
    "X[drg_copy.columns] = X[drg_copy.columns].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specified-membership",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tags = ['TAG_COMA','TAG_SEVERE','TAG_VENTILATED','TAG_SX','TAG_FAILURE','TAG_CANCER','TAG_ID','TAG_BREAST', \n",
    "#        'TAG_CARDIAC','TAG_CONNECTIVE_TISSUE','TAG_ENDOCRINE','TAG_ENT','TAG_GI','TAG_GU','TAG_HEME','TAG_HIV',\n",
    "#        'TAG_LIVER','TAG_NEURO','TAG_OB','TAG_ORTHO','TAG_RENAL','TAG_RESPIRATORY','TAG_SKIN_SOFT_TISSUE',\n",
    "#        'TAG_VASCULAR']\n",
    "#cols = tags + list(maps['diagnoses'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pregnant-party",
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap = ['STROKE','TRANSPLANT','NEONATE','DM','ELECTROLYTE_DX','HTN','MI','OD','PSYCH','TRAUMA','SEPSIS']\n",
    "\n",
    "for d,regx in maps['diagnoses'].items():\n",
    "    if d in overlap:\n",
    "        X[f'{d}'] = X.DIAGNOSIS.str.match(regx).fillna(0).astype(int,errors='ignore')\n",
    "    else:\n",
    "        X[f'TAG_{d}'] = X.DIAGNOSIS.str.match(regx).fillna(0).astype(int,errors='ignore')\n",
    "        \n",
    "# Merge overlapping columns\n",
    "for d in overlap:\n",
    "    X[f'TAG_{d}'] = X[[d,'TAG_'+d]].apply(lambda x: 1 if sum(x)>0 else 0,axis=1)\n",
    "    X.drop(d,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlling-palmer",
   "metadata": {},
   "source": [
    "### Drop any 1-level columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optional-breast",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_level_columns = [c for c in X.columns if len(X[c].unique())<2]\n",
    "print(one_level_columns)\n",
    "X = X.drop(one_level_columns,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bound-constraint",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last check for missing values\n",
    "X.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "radical-token",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identical-consideration",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop(['DIAGNOSIS','DIAGNOSIS_1','DOA'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appropriate-plumbing",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.to_csv('X_y_IV.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungry-algebra",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
